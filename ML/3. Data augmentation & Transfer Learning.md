## Data augmentation
Zmienianie pikseli danych bez zmiany etykiety.  Użyteczne przede wszystkim, gdy jest za mało danych.
### Metody
* Odbicia - trzeba uważać, np. przy znakach drogowych
* Przycinanie, przeskalowywanie
* Zmiana kontrastu
* Rotacje
* Rozciąganie
* Zakrzywienia obiektywu...

## Transfer Learning
Gdy jest za mało danych, by wytrenować sieć od zera, można wytrenować tylko jej część, używając sieci pre-trenowanej na innym (podobnym) zbiorze.
Gdy nasz zbiór danych jest bardzo mały, uczymy tylko ostatnie warstwy, używając sieci pre-trained jako feature extractor. Gdy nasz zbiór jest nieco większy, możemy wytrenować nie tylko ostatnie warstwy FC i softmax, ale też ostatnie warstwy konwolucyjne (finetuning). To, ile warstw będziemy uczyć, zależy nie tylko od rozmiaru naszych danych treningowych, ale też od **podobieństwa** danych, na których była uczona sieć, do naszych danych.
Transfer learning działa, bo płytsze warstwy są bardziej "ogólne", a głębsze uczą się bardziej specyficznych rzeczy. 
